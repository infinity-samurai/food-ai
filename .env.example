# ============================================================
# food-ai environment example
# Copy to:
#  - .env                 (for docker compose)
#  - frontend/.env.local  (for Next.js local dev)
# and adjust values as needed.
# ============================================================

# -----------------------
# Frontend (Next.js)
# -----------------------
# URL of the backend API that the browser calls.
NEXT_PUBLIC_API_BASE=http://localhost:8000

# -----------------------
# Backend + Worker (storage + DB)
# -----------------------
# For your requested first step, keep this as "local".
STORAGE_DRIVER=local

# Where uploaded images are stored when STORAGE_DRIVER=local.
# In docker compose we mount a shared /data volume, so these defaults work.
LOCAL_UPLOAD_DIR=/data/uploads

# SQLite path used by both backend + worker.
SQLITE_PATH=/data/app.db

# -----------------------
# Worker (nutrition DB + models)
# -----------------------
NUTRITION_DB_PATH=/app/nutrition_db/nutrition.json

# Model selection (downloads weights; inference is local, no external API calls).
CLIP_MODEL=openai/clip-vit-base-patch32
VLM_MODEL=vikhyatk/moondream2

# DEVICE=auto uses CUDA if available, else CPU.
DEVICE=auto

# Threshold for deciding food vs not-food from CLIP probability.
FOOD_THRESHOLD=0.6

# Worker polling interval (seconds) for queued jobs in SQLite.
POLL_INTERVAL_SECONDS=0.5

# -----------------------
# Optional: S3 mode (not needed for local uploads)
# -----------------------
# STORAGE_DRIVER=s3
# S3_BUCKET=your-bucket
# AWS_REGION=your-region
# AWS_ACCESS_KEY_ID=...
# AWS_SECRET_ACCESS_KEY=...
# S3_PREFIX=uploads/
# S3_PUBLIC_BASE_URL=https://your-cdn-or-bucket-domain/

